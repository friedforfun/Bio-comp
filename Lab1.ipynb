{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "## Basic idea for gradient descent\n",
    "### Not logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron(input, weights):\n",
    "    out = 0\n",
    "    for i in range(len(input)):\n",
    "        out += (input[i] * weights[i])\n",
    "    return out\n",
    "\n",
    "# \n",
    "def ele_mul(scalar, vector):\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(out)):\n",
    "        out[i] = vector[i] * scalar\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Pred: 0.8600000000000001\n",
      "Error: 0.01959999999999997\n",
      "Delta: -0.1399999999999999\n",
      "Weights: [0.1, 0.2, -0.1]\n",
      "Weight_Deltas: [-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Iteration: 2\n",
      "Pred: 0.9637574999999999\n",
      "Error: 0.0013135188062500048\n",
      "Delta: -0.036242500000000066\n",
      "Weights: [0.1119, 0.20091, -0.09832]\n",
      "Weight_Deltas: [-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
      "\n",
      "Iteration: 3\n",
      "Pred: 0.9906177228125002\n",
      "Error: 8.802712522307997e-05\n",
      "Delta: -0.009382277187499843\n",
      "Weights: [0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
      "Weight_Deltas: [-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature1 = [8.5, 9.5, 9.9, 9.0]\n",
    "feature2 = [0.65, 0.8, 0.8, 0.9]\n",
    "feature3 = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "# y\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "# Alpha is the learning rate\n",
    "alpha = 0.01\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [feature1[0], feature2[0], feature3[0]]\n",
    "\n",
    "for iter in range(3):\n",
    "    # yhat\n",
    "    pred = neuron(input, weights)\n",
    "    \n",
    "    # Mean squared loss function\n",
    "    error = (pred - true) ** 2\n",
    "    \n",
    "    # loss calculation\n",
    "    delta = pred - true\n",
    "    \n",
    "    \n",
    "    weight_deltas = ele_mul(delta, input)\n",
    "    \n",
    "    print(\"Iteration: \" + str(iter+1))\n",
    "    print(\"Pred: \"+ str(pred))\n",
    "    print(\"Error: \" + str(error))\n",
    "    print(\"Delta: \" + str(delta))\n",
    "    print(\"Weights: \" + str(weights))\n",
    "    print(\"Weight_Deltas: \" + str(weight_deltas))\n",
    "    print()\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        # change the weights by the alpha * how much each weight needs to change\n",
    "        weights[i] -= alpha*weight_deltas[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('diabetes.csv', sep=',', header='infer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Outcome').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = df.to_numpy()\n",
    "\n",
    "data = np.transpose(raw_data)\n",
    "\n",
    "data[8] # training labels (Y)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:  [  6.    148.     72.     35.      0.     33.6     0.627  50.      1.   ]\n",
      "Training data size:  (8, 500)\n",
      "Testing data size:  (8, 268)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.804065  ,  2.26906711,  0.62429218, -0.17645351, -0.93391565,\n",
       "       -0.206752  , -0.92034626,  0.14817312])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: slice upper bound is exclusive\n",
    "raw_training_data = data[:, 0:500]\n",
    "raw_testing_data = data[:, 500:]\n",
    "\n",
    "print(\"Raw: \", raw_training_data[:, 0])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "training_data = preprocessing.scale(raw_training_data[0:8, :]) # ~68%\n",
    "testing_data = preprocessing.scale(raw_testing_data[0:8, :]) # ~68%\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# training_data = min_max_scaler.fit_transform(raw_training_data[0:8, :]) # ~61%\n",
    "# testing_data = min_max_scaler.fit_transform(raw_testing_data[0:8, :]) # ~61%\n",
    "\n",
    "print(\"Training data size: \", training_data.shape)\n",
    "print(\"Testing data size: \", testing_data.shape)\n",
    "\n",
    "training_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_vec = []\n",
    "loss_vec = []\n",
    "def store_loss(loss, iteration):\n",
    "    iteration_vec.append(iteration)\n",
    "    loss_vec.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activation function\n",
    "def sigmoid(input_vector, weight_vector, bias):\n",
    "    z = np.dot(input_vector, weight_vector) + bias\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "# loss function\n",
    "def wierd_broken_loss(y, yhat):\n",
    "    return (-y * np.log(yhat) - (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def loss(y, yhat):\n",
    "    #if yhat == 1.0:\n",
    "    #    return 1\n",
    "    #if yhat == 0:\n",
    "    #    return 0.0\n",
    "    return -(y* np.log(yhat) + (1-y) * np.log(1-yhat))\n",
    "\n",
    "# From lab sheet tutorial\n",
    "def loss_other(y, h):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def dz_calc(pred, actual):\n",
    "    return pred - actual\n",
    "    \n",
    "def update_dweights(features, dz, derivative_weights):\n",
    "    for i in range(len(derivative_weights)):\n",
    "        derivative_weights[i] += features[i] * dz\n",
    "    return derivative_weights\n",
    "\n",
    "def update_bias(db, dz):\n",
    "    db += dz\n",
    "    return db\n",
    "\n",
    "# Init random weights and bias\n",
    "weights = np.random.rand(training_data.shape[0])\n",
    "initial_weights = weights\n",
    "bias = np.random.rand(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent algorithm from slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight derivatives:  [-8.10456912e-05 -4.42656443e-07  9.58572689e-07  3.43319002e-07\n",
      " -4.36338620e-07 -4.92483326e-06  7.34888803e-05  1.20587475e-05]\n",
      "Weights on iteration  0 :  [ 6.10380521  0.43798348 -0.57368027  0.22779475  0.41117973  1.41205133\n",
      " -3.16406436 -0.85506989]\n",
      "Loss:  0.5939157739759253\n",
      "Weight derivatives:  [-6.13992701e-05 -3.38594778e-07  7.31449036e-07  2.64376896e-07\n",
      " -3.29598157e-07 -3.74135365e-06  5.56654276e-05  9.14756315e-06]\n",
      "Weights on iteration  1000 :  [ 6.1462593   0.43821699 -0.57418401  0.22761333  0.41140768  1.4146347\n",
      " -3.20255722 -0.86139077]\n",
      "Loss:  0.5939101834372579\n",
      "Weight derivatives:  [-4.65270636e-05 -2.57580462e-07  5.57609565e-07  2.02623709e-07\n",
      " -2.49693412e-07 -2.84103334e-06  4.21764499e-05  6.93868770e-06]\n",
      "Weights on iteration  2000 :  [ 6.17842618  0.43839473 -0.57456837  0.22747403  0.41158033  1.41659683\n",
      " -3.23171821 -0.86618553]\n",
      "Loss:  0.5939069743344637\n",
      "Weight derivatives:  [-3.52637990e-05 -1.95802935e-07  4.24533177e-07  1.54880641e-07\n",
      " -1.89209221e-07 -2.15666615e-06  3.19631569e-05  5.26290656e-06]\n",
      "Weights on iteration  3000 :  [ 6.20280383  0.43852989 -0.57486118  0.22736741  0.41171114  1.41808655\n",
      " -3.25381527 -0.86982238]\n",
      "Loss:  0.5939051313887811\n",
      "Weight derivatives:  [-2.67309505e-05 -1.48757196e-07  3.22903205e-07  1.18153645e-07\n",
      " -1.43404364e-07 -1.63675780e-06  2.42271226e-05  3.99169034e-06]\n",
      "Weights on iteration  4000 :  [ 6.22128146  0.4386326  -0.57508401  0.227286    0.41181027  1.41921728\n",
      " -3.27056278 -0.87258084]\n",
      "Loss:  0.5939040726389385\n",
      "Weight derivatives:  [-2.02650112e-05 -1.12966338e-07  2.45424732e-07  9.00036209e-08\n",
      " -1.08704199e-07 -1.24195900e-06  1.83657728e-05  3.02743951e-06]\n",
      "Weights on iteration  5000 :  [ 6.23528879  0.43871062 -0.57525343  0.22722394  0.41188542  1.42007535\n",
      " -3.2832577  -0.87467298]\n",
      "Loss:  0.593903464237836\n",
      "Weight derivatives:  [-1.53686386e-05 -8.57822581e-08  1.86486556e-07  6.85039576e-08\n",
      " -8.24325418e-08 -9.42520917e-07  1.39276803e-05  2.29670353e-06]\n",
      "Weights on iteration  6000 :  [ 6.2458991   0.4387698  -0.57538206  0.22717673  0.41194233  1.42072583\n",
      " -3.29287341 -0.87625834]\n",
      "Loss:  0.5939031148164495\n",
      "Bias:  1.4098671710943211\n"
     ]
    }
   ],
   "source": [
    "weights_old = np.array([ 0.7922078, 0.45199038, -0.08072242, 0.48454824, 0.505596, 0.5769389, 0.76302185, 0.50641925])\n",
    "weights_old_a = np.array([3.40068449, 0.4333755, -0.55011185, 0.22646619, 0.40094553, 1.27276349, -0.72093493, -0.46318842])\n",
    "weights = np.array([ 6.10375658, 0.43798321, -0.57367969, 0.22779496, 0.41117947, 1.41204838, -3.16402027, -0.85506265])\n",
    "bias = 1.4121690269083802\n",
    "\n",
    "def train_network(iterations, weights, bias):\n",
    "\n",
    "    # Alpha is step size (learning rate)\n",
    "    alpha = 0.6\n",
    "\n",
    "    # m is the amount of training data\n",
    "    m = training_data.shape[1]\n",
    "\n",
    "    for j in range(iterations):\n",
    "        \n",
    "        # l is the average of all the losses\n",
    "        l = 0.0\n",
    "        \n",
    "        # all derivitive weights and deriviative bias start at 0\n",
    "        derivative_weights = np.zeros(training_data.shape[0])\n",
    "        db = 0.0\n",
    "\n",
    "        for i in range(m):\n",
    "            # grab features\n",
    "            features = training_data[0:8, i]\n",
    "            # make prediction\n",
    "            yhat = sigmoid(features, weights, bias)\n",
    "            # get actual value\n",
    "            y = raw_training_data[8, i]\n",
    "            # calculate the loss\n",
    "            l += loss(y, yhat)\n",
    "            # find the derivative of the activation function\n",
    "            dz = dz_calc(yhat, y)\n",
    "            # calculate the deriviative of each weight and the bias\n",
    "            for k in range(len(derivative_weights)):\n",
    "                derivative_weights[k] += features[k] * dz\n",
    "            db += dz\n",
    "\n",
    "        # Calculate average for loss, derivarive bias, and all derivative weights\n",
    "        l /= m\n",
    "        for i in range(len(derivative_weights)):\n",
    "            derivative_weights[i] /= m\n",
    "        db /= m\n",
    "        \n",
    "        store_loss(l, j)\n",
    "\n",
    "        # Update weights with the derivative weight by learning rate\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = weights[i]-alpha*derivative_weights[i]\n",
    "        bias = bias - alpha*db\n",
    "        \n",
    "        \n",
    "\n",
    "        if j%1000 == 0:\n",
    "            print(\"Weight derivatives: \", derivative_weights)\n",
    "            print(\"Weights on iteration \", j, \": \", weights)\n",
    "            print(\"Loss: \", l)\n",
    "        \n",
    "        elif j == iterations-1:\n",
    "            print(\"Weight derivatives: \", derivative_weights)\n",
    "            print(\"Weights on iteration \", j+1, \": \", weights)\n",
    "            print(\"Loss: \", l)\n",
    "            print(\"Bias: \", bias)\n",
    "        \n",
    "\n",
    "# clear loss_vec && iterations_vec\n",
    "iteration_vec = []\n",
    "loss_vec = []\n",
    "\n",
    "train_network(6000, weights, bias)\n",
    "last_train = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good predictions:  182\n",
      "Total predictions:  268\n",
      "67.91044776119402 %\n"
     ]
    }
   ],
   "source": [
    "def test_weights(weights, bias):\n",
    "    m = testing_data.shape[1]\n",
    "    good_pred = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        features = testing_data[0:8, i]\n",
    "        # make prediction\n",
    "        yhat = sigmoid(features, weights, bias)\n",
    "        #print(\"Prediction\", yhat)\n",
    "        # get actual value\n",
    "        y = raw_testing_data[8, i]\n",
    "        #print(\"Actual\", y)\n",
    "\n",
    "        #if np.isclose(y, yhat):\n",
    "        #    print(\"TRUE\")\n",
    "        #    good_pred += 1\n",
    "        \n",
    "        if yhat < 0.5 and y == 0.0:\n",
    "            good_pred += 1\n",
    "        elif yhat >= 0.5 and y == 1.0:\n",
    "            good_pred += 1\n",
    "\n",
    "    print(\"Good predictions: \", good_pred)\n",
    "    print(\"Total predictions: \", m)\n",
    "    \n",
    "    print(good_pred/m*100, \"%\")\n",
    "        \n",
    "test_weights(weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24984c84a00>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "pyplot.plot(iteration_vec, loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:  [  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
      "Weights:  [0.493796   0.289154   0.369878   0.461918   0.370004   0.4426352\n",
      " 0.49916111 0.440312  ]\n",
      "Dot product:  125.75703073597\n",
      "yhat:  1.177059699480968e-41\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'yhat_random_bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-3ae7139e28a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m220\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yhat: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yhat random bias: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat_random_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat_random_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yhat_random_bias' is not defined"
     ]
    }
   ],
   "source": [
    "one_column = training_data[0:8, 0]\n",
    "y = training_data[8, 0]\n",
    "\n",
    "print(\"column: \", one_column)\n",
    "print(\"Weights: \", weights)\n",
    "print(\"Dot product: \", np.dot(one_column, weights))\n",
    "yhat = sigmoid(one_column, weights, -220)\n",
    "print(\"yhat: \", yhat)\n",
    "print(\"yhat random bias: \", yhat_random_bias)\n",
    "loss = loss(y, yhat_random_bias)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(one_column, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sigmoid(np.array([0.5, 0.5]), np.array([1, 1]), 0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(X, weight):\n",
    "    z = np.dot(X, weight) + 0\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "sig(0.5, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "z = np.array([ 0.2, 0.4, 0.1])\n",
    "g = expit(z)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
