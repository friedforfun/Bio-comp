
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SamModel.model &#8212; Biologically Inspired Computation Coursework 1.0 documentation</title>
    <link rel="stylesheet" href="../../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Biologically Inspired Computation Coursework 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">SamModel.model</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for SamModel.model</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">IntEnum</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">activations</span> <span class="k">as</span> <span class="n">activ</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">loss</span>

<div class="viewcode-block" id="ActivationFunction"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ActivationFunction">[docs]</a><span class="k">class</span> <span class="nc">ActivationFunction</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">NULL</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">SIGMOID</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">HYPERBOLIC_TANGENT</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">COSINE</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">GAUSSIAN</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">RELU</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">SOFTMAX</span> <span class="o">=</span> <span class="mi">6</span></div>

<span class="n">activation_picker</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">NULL</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">null</span><span class="p">,</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">SIGMOID</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">HYPERBOLIC_TANGENT</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">hyperbolic_tangent</span><span class="p">,</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">COSINE</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">cosine</span><span class="p">,</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">GAUSSIAN</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">gaussian</span><span class="p">,</span>
    <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">RELU</span><span class="p">:</span> <span class="n">activ</span><span class="o">.</span><span class="n">relu</span>
<span class="p">}</span>

<span class="n">activation_enum</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;null&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">NULL</span><span class="p">,</span>
    <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">SIGMOID</span><span class="p">,</span>
    <span class="s2">&quot;hyperbolictangent&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">HYPERBOLIC_TANGENT</span><span class="p">,</span>
    <span class="s2">&quot;tan&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">HYPERBOLIC_TANGENT</span><span class="p">,</span>
    <span class="s2">&quot;cosine&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">COSINE</span><span class="p">,</span>
    <span class="s2">&quot;gaussian&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">GAUSSIAN</span><span class="p">,</span>
    <span class="s2">&quot;relu&quot;</span><span class="p">:</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">RELU</span>
<span class="p">}</span>

<span class="n">loss_picker</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;mse&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">,</span>
    <span class="s1">&#39;meansquarederror&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean_squared_error</span>
<span class="p">}</span>

<div class="viewcode-block" id="weight_matrix"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.weight_matrix">[docs]</a><span class="k">def</span> <span class="nf">weight_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a numpy array of random weights with the specified size</span>

<span class="sd">        :param x: number of rows in the desired matrix</span>
<span class="sd">        :type x: int</span>
<span class="sd">        :param y: number of columns in the desired matrix</span>
<span class="sd">        :type y: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span></div>

<div class="viewcode-block" id="calculate_one_layer"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.calculate_one_layer">[docs]</a><span class="k">def</span> <span class="nf">calculate_one_layer</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate the output of a single layer</span>

<span class="sd">    :param input_matrix: The input matrix to the layer</span>
<span class="sd">    :type input_matrix: numpy.ndarray</span>
<span class="sd">    :param layer: The layer being calculated</span>
<span class="sd">    :type layer: Layer</span>
<span class="sd">    :raises Exception: Dot product rule violation</span>
<span class="sd">    :raises Exception: Bias doesnt match number of neurons in layer</span>
<span class="sd">    :return: Returns the output of each neuron in the layer</span>
<span class="sd">    :rtype: numpy.ndarray</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">input_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;The number of columns in the input_matrix must equal the number of rows in the weight_matrix.&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;The number of elements in the bias vector should be the same as the number of columns in the weigth matrix.&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span>
    <span class="k">return</span> <span class="n">apply_activation</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">activation</span><span class="p">)</span></div>

<div class="viewcode-block" id="apply_activation"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.apply_activation">[docs]</a><span class="k">def</span> <span class="nf">apply_activation</span><span class="p">(</span><span class="n">weighted_sum</span><span class="p">,</span> <span class="n">activation_func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply activation function to matrix</span>

<span class="sd">    :param weighted_sum: The matrix of the sum of input * weight + bias</span>
<span class="sd">    :type weighted_sum: numpy.ndarray</span>
<span class="sd">    :param activation_func: The activation function identifier</span>
<span class="sd">    :type activation_func: Enum.ActivationFunction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">af</span> <span class="o">=</span> <span class="n">pick_activation</span><span class="p">(</span><span class="n">activation_func</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">af</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Invalid activation function&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">af</span><span class="p">(</span><span class="n">weighted_sum</span><span class="p">)</span></div>

<div class="viewcode-block" id="apply_loss"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.apply_loss">[docs]</a><span class="k">def</span> <span class="nf">apply_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply the loss function</span>

<span class="sd">    :param y: the actual labels</span>
<span class="sd">    :type y: numpy.array</span>
<span class="sd">    :param y_hat: the predicted labels</span>
<span class="sd">    :type y_hat: numpy.array</span>
<span class="sd">    :param loss_func: name of the loss function, defaults to &#39;MSE&#39;</span>
<span class="sd">    :type loss_func: str, optional</span>
<span class="sd">    :return: The value calculated by the loss function</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_picker</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">loss_func</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="pick_activation"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.pick_activation">[docs]</a><span class="k">def</span> <span class="nf">pick_activation</span><span class="p">(</span><span class="n">activation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Select activation function to use</span>

<span class="sd">    :param activation: The activation function identifier</span>
<span class="sd">    :type activation: Enum.ActivationFunction</span>
<span class="sd">    :return: reference to the activation function defintion</span>
<span class="sd">    :rtype: fn</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">activation_picker</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span></div>

<div class="viewcode-block" id="enumerate_activation"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.enumerate_activation">[docs]</a><span class="k">def</span> <span class="nf">enumerate_activation</span><span class="p">(</span><span class="n">activation_string</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Enumerate the activation function</span>

<span class="sd">    :param activation_string: string representing the activation function</span>
<span class="sd">    :type activation_string: string</span>
<span class="sd">    :return: The enumerated activation function</span>
<span class="sd">    :rtype: Enum.ActivationFunction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">activation_string</span> <span class="o">=</span> <span class="n">activation_string</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">activation_enum</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation_string</span><span class="p">,</span> <span class="n">ActivationFunction</span><span class="o">.</span><span class="n">NULL</span><span class="p">)</span></div>


<div class="viewcode-block" id="ANN"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN">[docs]</a><span class="k">class</span> <span class="nc">ANN</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Artificial Neural Network class Implementation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Construct a new sequential Artificial Neural Network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">=</span><span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_column_size</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span><span class="o">=</span><span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_hat</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="s1">&#39;MSE&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="ANN.add"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN.add">[docs]</a>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a new layer to the Neural Network</span>

<span class="sd">        :param layer: Add an instance of the layer class</span>
<span class="sd">        :type layer: Layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isclass</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Parameter must be an instance of the Layer class.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">+</span> <span class="p">[</span><span class="n">layer</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span> <span class="o">=</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="ANN.set_training_input"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN.set_training_input">[docs]</a>    <span class="k">def</span> <span class="nf">set_training_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_matrix</span><span class="p">,</span> <span class="n">result_vector</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Provide the input data to the ANN</span>

<span class="sd">        :param input_matrix: The input matrix</span>
<span class="sd">        :type input_matrix: np.ndarray</span>
<span class="sd">        :param result_vector: A vector or results. Specifies the &#39;Y&#39; values to calculate the loss when training</span>
<span class="sd">        :type result_vector: numpy.ndarray</span>
<span class="sd">        :raises Exception: If input matrix columns doesnt match already configured columns</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">result_vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Number of rows in the input matrix and result vector are not compatible&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_column_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_column_size</span> <span class="o">=</span> <span class="n">input_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">input_matrix</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_column_size</span> <span class="o">==</span> <span class="n">input_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">input_matrix</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Weights might have been generated for a different shape input, please check the columns of your input&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">result_vector</span>    </div>
        
<div class="viewcode-block" id="ANN.compile"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN.compile">[docs]</a>    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compile the Neural Network so it is ready for training or inference</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Must define the size of the input matrix.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;The ANN needs at least 1 layer.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__generate_weights__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model Compiled!&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ANN.one_pass"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN.one_pass">[docs]</a>    <span class="k">def</span> <span class="nf">one_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;One pass of data in input through the Neural Network</span>

<span class="sd">        :raises Exception: Not Compiled exception</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;The neural network must be compiled before performing training or inference.&quot;</span><span class="p">)</span>
        <span class="c1"># Input layer special case</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">calculate_one_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Hidden layers -&gt; output layer</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">calculate_one_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">apply_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">)</span></div>

<div class="viewcode-block" id="ANN.set_loss_function"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.ANN.set_loss_function">[docs]</a>    <span class="k">def</span> <span class="nf">set_loss_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the loss to the specified function</span>

<span class="sd">        :param loss: The loss function to use</span>
<span class="sd">        :type loss: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">loss_picker</span><span class="o">.</span><span class="n">has_key</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;There is no loss function defined for this key&#39;</span><span class="p">)</span></div>
        
    <span class="k">def</span> <span class="nf">__generate_weights__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates the weight matrices &amp; bias vectors for the ANN Layers</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># raise exception if no input</span>
        
        <span class="c1"># special case for weights &amp; bias from input layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weight_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span>
        
        <span class="c1"># Construct weight matrices &amp; bias of each layer</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weight_matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">neurons</span><span class="p">)</span></div>
        

<div class="viewcode-block" id="Layer"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.Layer">[docs]</a><span class="k">class</span> <span class="nc">Layer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Layer class used to add layers to the ANN</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neuron_count</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constuctor for Layer class</span>

<span class="sd">        :param neurons: The number of neurons in the layer</span>
<span class="sd">        :type neurons: int</span>
<span class="sd">        :param activation: The activation funciton for the layer, defaults to &quot;null&quot;</span>
<span class="sd">        :type activation: str, optional</span>
<span class="sd">        :param use_bias: If you use a bias, defaults to True</span>
<span class="sd">        :type use_bias: bool, optional</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span> <span class="o">=</span> <span class="n">neuron_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">enumerate_activation</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="kc">None</span>
    
<div class="viewcode-block" id="Layer.to_vec"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.Layer.to_vec">[docs]</a>    <span class="k">def</span> <span class="nf">to_vec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">return</span>  <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">))</span></div>

<div class="viewcode-block" id="Layer.from_vec"><a class="viewcode-back" href="../../SamModel.html#SamModel.model.Layer.from_vec">[docs]</a>    <span class="k">def</span> <span class="nf">from_vec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>

</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Biologically Inspired Computation Coursework 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">SamModel.model</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Sam Fay-Hunt, Kamil Szymczak.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
    </div>
  </body>
</html>