{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "## Basic idea for gradient descent\n",
    "### Not logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron(input, weights):\n",
    "    out = 0\n",
    "    for i in range(len(input)):\n",
    "        out += (input[i] * weights[i])\n",
    "    return out\n",
    "\n",
    "# \n",
    "def ele_mul(scalar, vector):\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(out)):\n",
    "        out[i] = vector[i] * scalar\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Pred: 0.8600000000000001\n",
      "Error: 0.01959999999999997\n",
      "Delta: -0.1399999999999999\n",
      "Weights: [0.1, 0.2, -0.1]\n",
      "Weight_Deltas: [-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Iteration: 2\n",
      "Pred: 0.9637574999999999\n",
      "Error: 0.0013135188062500048\n",
      "Delta: -0.036242500000000066\n",
      "Weights: [0.1119, 0.20091, -0.09832]\n",
      "Weight_Deltas: [-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
      "\n",
      "Iteration: 3\n",
      "Pred: 0.9906177228125002\n",
      "Error: 8.802712522307997e-05\n",
      "Delta: -0.009382277187499843\n",
      "Weights: [0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
      "Weight_Deltas: [-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature1 = [8.5, 9.5, 9.9, 9.0]\n",
    "feature2 = [0.65, 0.8, 0.8, 0.9]\n",
    "feature3 = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "# y\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "# Alpha is the learning rate\n",
    "alpha = 0.01\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [feature1[0], feature2[0], feature3[0]]\n",
    "\n",
    "for iter in range(3):\n",
    "    # yhat\n",
    "    pred = neuron(input, weights)\n",
    "    \n",
    "    # Mean squared loss function\n",
    "    error = (pred - true) ** 2\n",
    "    \n",
    "    # loss calculation\n",
    "    delta = pred - true\n",
    "    \n",
    "    \n",
    "    weight_deltas = ele_mul(delta, input)\n",
    "    \n",
    "    print(\"Iteration: \" + str(iter+1))\n",
    "    print(\"Pred: \"+ str(pred))\n",
    "    print(\"Error: \" + str(error))\n",
    "    print(\"Delta: \" + str(delta))\n",
    "    print(\"Weights: \" + str(weights))\n",
    "    print(\"Weight_Deltas: \" + str(weight_deltas))\n",
    "    print()\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        # change the weights by the alpha * how much each weight needs to change\n",
    "        weights[i] -= alpha*weight_deltas[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('diabetes.csv', sep=',', header='infer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Outcome').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = df.to_numpy()\n",
    "\n",
    "data = np.transpose(raw_data)\n",
    "\n",
    "data[8] # training labels (Y)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:  [  6.    148.     72.     35.      0.     33.6     0.627  50.      1.   ]\n",
      "Training data size:  (8, 500)\n",
      "Testing data size:  (8, 268)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.804065  ,  2.26906711,  0.62429218, -0.17645351, -0.93391565,\n",
       "       -0.206752  , -0.92034626,  0.14817312])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: slice upper bound is exclusive\n",
    "raw_training_data = data[:, 0:500]\n",
    "raw_testing_data = data[:, 500:]\n",
    "\n",
    "print(\"Raw: \", raw_training_data[:, 0])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "training_data = preprocessing.scale(raw_training_data[0:8, :], axis=0) # ~68%\n",
    "testing_data = preprocessing.scale(raw_testing_data[0:8, :], axis=0) # ~68%\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# training_data = min_max_scaler.fit_transform(raw_training_data[0:8, :]) # ~61%\n",
    "# testing_data = min_max_scaler.fit_transform(raw_testing_data[0:8, :]) # ~61%\n",
    "\n",
    "print(\"Training data size: \", training_data.shape)\n",
    "print(\"Testing data size: \", testing_data.shape)\n",
    "\n",
    "training_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_vec = []\n",
    "loss_vec = []\n",
    "def store_loss(loss, iteration):\n",
    "    iteration_vec.append(iteration)\n",
    "    loss_vec.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activation function\n",
    "def sigmoid(input_vector, weight_vector, bias):\n",
    "    z = np.dot(input_vector, weight_vector) + bias\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "# loss function\n",
    "def wierd_broken_loss(y, yhat):\n",
    "    return (-y * np.log(yhat) - (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def loss(y, yhat):\n",
    "    #if yhat == 1.0:\n",
    "    #    return 1.0\n",
    "    #if yhat == 0:\n",
    "    #    return 0.0\n",
    "    return -(y * np.log(yhat) + (1-y) * np.log(1-yhat))\n",
    "\n",
    "# From lab sheet tutorial\n",
    "def loss_other(y, h):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def dz_calc(pred, actual):\n",
    "    return pred - actual\n",
    "    \n",
    "def update_dweights(features, dz, derivative_weights):\n",
    "    for i in range(len(derivative_weights)):\n",
    "        derivative_weights[i] += features[i] * dz\n",
    "    return derivative_weights\n",
    "\n",
    "def update_bias(db, dz):\n",
    "    db += dz\n",
    "    return db\n",
    "\n",
    "# Init random weights and bias\n",
    "weights = np.random.rand(training_data.shape[0])\n",
    "initial_weights = weights\n",
    "bias = np.random.rand(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent algorithm from slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight derivatives:  [-8.10456912e-05 -4.42656443e-07  9.58572689e-07  3.43319002e-07\n",
      " -4.36338620e-07 -4.92483326e-06  7.34888803e-05  1.20587475e-05]\n",
      "Weights on iteration  0 :  [ 6.10380521  0.43798348 -0.57368027  0.22779475  0.41117973  1.41205133\n",
      " -3.16406436 -0.85506989]\n",
      "Loss:  0.5939157739759253\n",
      "Weight derivatives:  [-7.88251347e-05 -4.32714161e-07  9.32403188e-07  3.34882764e-07\n",
      " -4.23286498e-07 -4.79142923e-06  7.14751527e-05  1.17301260e-05]\n",
      "Weights on iteration  100 :  [ 6.10860034  0.43800979 -0.57373696  0.2277744   0.41120548  1.41234276\n",
      " -3.16841242 -0.85578341]\n",
      "Loss:  0.5939150652345487\n",
      "Weight derivatives:  [-7.66662255e-05 -4.21103721e-07  9.07672541e-07  3.26246149e-07\n",
      " -4.11674360e-07 -4.66161908e-06  6.95162025e-05  1.14105015e-05]\n",
      "Weights on iteration  200 :  [ 6.11326413  0.4380354  -0.57379215  0.22775457  0.41123053  1.4126263\n",
      " -3.1726413  -0.85647748]\n",
      "Loss:  0.5939143947949822\n",
      "Weight derivatives:  [-7.45666709e-05 -4.09796578e-07  8.83572968e-07  3.17826148e-07\n",
      " -4.00383537e-07 -4.53529974e-06  6.76111800e-05  1.10995716e-05]\n",
      "Weights on iteration  300 :  [ 6.1178002   0.43806032 -0.57384588  0.22773525  0.41125488  1.41290215\n",
      " -3.17675428 -0.85715265]\n",
      "Loss:  0.5939137605832371\n",
      "Weight derivatives:  [-7.25248265e-05 -3.98787764e-07  8.60093880e-07  3.09612383e-07\n",
      " -3.89404341e-07 -4.41237939e-06  6.57585888e-05  1.07971030e-05]\n",
      "Weights on iteration  400 :  [ 6.12221204  0.43808457 -0.57389818  0.22771643  0.41127857  1.41317053\n",
      " -3.18075456 -0.85780942]\n",
      "Loss:  0.5939131606379527\n",
      "Weight derivatives:  [-7.05390944e-05 -3.88070047e-07  8.37220960e-07  3.01598656e-07\n",
      " -3.78727863e-07 -4.29276816e-06  6.39569739e-05  1.05028669e-05]\n",
      "Weights on iteration  500 :  [ 6.12650309  0.43810817 -0.57394909  0.2276981   0.41130161  1.41343163\n",
      " -3.18464524 -0.85844829]\n",
      "Loss:  0.5939125931042483\n",
      "Weight derivatives:  [-6.86079217e-05 -3.77636066e-07  8.14939710e-07  2.93780227e-07\n",
      " -3.68345602e-07 -4.17637827e-06  6.22049217e-05  1.02166400e-05]\n",
      "Weights on iteration  600 :  [ 6.13067665  0.43813114 -0.57399864  0.22768024  0.41132402  1.41368565\n",
      " -3.18842932 -0.85906975]\n",
      "Loss:  0.5939120562279242\n",
      "Weight derivatives:  [-6.67297993e-05 -3.67478567e-07  7.93235811e-07  2.86152851e-07\n",
      " -3.58249349e-07 -4.06312417e-06  6.05010578e-05  9.93820495e-06]\n",
      "Weights on iteration  700 :  [ 6.13473596  0.43815349 -0.57404688  0.22766284  0.41134581  1.41393279\n",
      " -3.19210975 -0.85967427]\n",
      "Loss:  0.5939115483499717\n",
      "Weight derivatives:  [-6.49032605e-05 -3.57590449e-07  7.72095205e-07  2.78712473e-07\n",
      " -3.48431141e-07 -3.95292249e-06  5.88440467e-05  9.66735013e-06]\n",
      "Weights on iteration  800 :  [ 6.13868415  0.43817524 -0.57409383  0.2276459   0.41136701  1.41417322\n",
      " -3.19568938 -0.86026232]\n",
      "Loss:  0.593911067901393\n",
      "Weight derivatives:  [-6.31268793e-05 -3.47964776e-07  7.51504112e-07  2.71455123e-07\n",
      " -3.38883248e-07 -3.84569202e-06  5.72325905e-05  9.40386964e-06]\n",
      "Weights on iteration  900 :  [ 6.14252427  0.4381964  -0.57413953  0.2276294   0.41138763  1.41440713\n",
      " -3.19917097 -0.86083434]\n",
      "Loss:  0.593910613398296\n",
      "Weight derivatives:  [-6.14163092e-05 -3.38687234e-07  7.31646977e-07  2.64446804e-07\n",
      " -3.29689732e-07 -3.74238297e-06  5.56808840e-05  9.15009134e-06]\n",
      "Weights on iteration  1000 :  [ 6.14622246  0.43821679 -0.57418357  0.22761349  0.41140748  1.41463246\n",
      " -3.20252382 -0.86138528]\n",
      "Loss:  0.5939101876198044\n",
      "Bias:  1.4114772304912575\n"
     ]
    }
   ],
   "source": [
    "weights_old = np.array([ 0.7922078, 0.45199038, -0.08072242, 0.48454824, 0.505596, 0.5769389, 0.76302185, 0.50641925])\n",
    "weights_old_a = np.array([3.40068449, 0.4333755, -0.55011185, 0.22646619, 0.40094553, 1.27276349, -0.72093493, -0.46318842])\n",
    "weights = np.array([ 6.10375658, 0.43798321, -0.57367969, 0.22779496, 0.41117947, 1.41204838, -3.16402027, -0.85506265])\n",
    "bias = 1.4121690269083802\n",
    "\n",
    "def train_network(iterations, weights, bias):\n",
    "\n",
    "    # Alpha is step size (learning rate)\n",
    "    alpha = 0.6\n",
    "\n",
    "    # m is the amount of training data\n",
    "    m = training_data.shape[1]\n",
    "\n",
    "    for j in range(iterations):\n",
    "        \n",
    "        # l is the average of all the losses\n",
    "        l = 0.0\n",
    "        \n",
    "        # all derivitive weights and deriviative bias start at 0\n",
    "        derivative_weights = np.zeros(training_data.shape[0])\n",
    "        db = 0.0\n",
    "\n",
    "        for i in range(m):\n",
    "            # grab features\n",
    "            features = training_data[0:8, i]\n",
    "            # make prediction\n",
    "            yhat = sigmoid(features, weights, bias)\n",
    "            # get actual value\n",
    "            y = raw_training_data[8, i]\n",
    "            # calculate the loss\n",
    "            l += loss(y, yhat)\n",
    "            # find the derivative of the activation function\n",
    "            dz = dz_calc(yhat, y)\n",
    "            # calculate the deriviative of each weight and the bias\n",
    "            for k in range(len(derivative_weights)):\n",
    "                derivative_weights[k] += features[k] * dz\n",
    "            db += dz\n",
    "\n",
    "        # Calculate average for loss, derivarive bias, and all derivative weights\n",
    "        l /= m\n",
    "        for i in range(len(derivative_weights)):\n",
    "            derivative_weights[i] /= m\n",
    "        db /= m\n",
    "        \n",
    "        store_loss(l, j)\n",
    "\n",
    "        # Update weights with the derivative weight by learning rate\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = weights[i]-alpha*derivative_weights[i]\n",
    "        bias = bias - alpha*db\n",
    "        \n",
    "        \n",
    "\n",
    "        if j%100 == 0:\n",
    "            print(\"Weight derivatives: \", derivative_weights)\n",
    "            print(\"Weights on iteration \", j, \": \", weights)\n",
    "            print(\"Loss: \", l)\n",
    "        \n",
    "        elif j == iterations-1:\n",
    "            print(\"Weight derivatives: \", derivative_weights)\n",
    "            print(\"Weights on iteration \", j+1, \": \", weights)\n",
    "            print(\"Loss: \", l)\n",
    "            print(\"Bias: \", bias)\n",
    "        \n",
    "\n",
    "# clear loss_vec && iterations_vec\n",
    "iteration_vec = []\n",
    "loss_vec = []\n",
    "\n",
    "train_network(1000, weights, bias)\n",
    "last_train = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good predictions:  182\n",
      "Total predictions:  268\n",
      "67.91044776119402 %\n"
     ]
    }
   ],
   "source": [
    "def test_weights(weights, bias):\n",
    "    m = testing_data.shape[1]\n",
    "    good_pred = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        features = testing_data[0:8, i]\n",
    "        # make prediction\n",
    "        yhat = sigmoid(features, weights, bias)\n",
    "        #print(\"Prediction\", yhat)\n",
    "        # get actual value\n",
    "        y = raw_testing_data[8, i]\n",
    "        #print(\"Actual\", y)\n",
    "\n",
    "        #if np.isclose(y, yhat):\n",
    "        #    print(\"TRUE\")\n",
    "        #    good_pred += 1\n",
    "        \n",
    "        if yhat < 0.5 and y == 0.0:\n",
    "            good_pred += 1\n",
    "        elif yhat >= 0.5 and y == 1.0:\n",
    "            good_pred += 1\n",
    "\n",
    "    print(\"Good predictions: \", good_pred)\n",
    "    print(\"Total predictions: \", m)\n",
    "    \n",
    "    print(good_pred/m*100, \"%\")\n",
    "        \n",
    "test_weights(weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eecbde7910>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "pyplot.plot(iteration_vec, loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
